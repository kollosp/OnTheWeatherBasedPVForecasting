from typing import Tuple
if __name__ == "__main__": import __config__

import numpy as np
from dimensions import ChainDimension
from dimensions import Elevation
from dimensions import DayProgress
from dimensions import OCI, VCI, ACI
from dimensions import OCIModel
from dimensions import SolarDayProgress
from dimensions import Quantization
from dimensions import MeanBySolarDay
from dimensions import MathTransform
from dimensions import RollingAverage
from dimensions import Vectorize

import pandas as pd
import os

from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from matplotlib import pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error, max_error

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Activation
from tensorflow.keras import Input

# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
# from tensorflow.keras.utils import np_utils


from SlidingWindowExperiment import SlidingWindowExperimentBase
from SlidingWindowExperiment import SlidingWindowExperimentTrajectoryBase

import matplotlib.dates as mdates

class SWE(SlidingWindowExperimentBase):
    def __init__(self, **kwargs):
        super(SWE, self).__init__(**kwargs)
        latitude_degrees = kwargs.get("latitude_degrees")
        longitude_degrees = kwargs.get("longitude_degrees")
        #create extra dimension generators
        self.chain = ChainDimension(transformers=[
            DayProgress(dimension_name="Day%"),
            Elevation(
                dimension_name="Elevation",
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            SolarDayProgress(
                scale=0.01,
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            RollingAverage(window_size=36, dimension_name="Averaged pv production"),
            VCI(
                window_size=12,
                dimension_name="VCI"),
            OCIModel(
                dimension_name="PV profile",
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            OCI(
                window_size=12,
                dimension_name="OCI",
                base_dimensions=["PV profile"],
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            MeanBySolarDay(dimension_name="OCId", base_dimensions=["OCI"],
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            Quantization(k=4, descriptive_params=True, dimension_name="qOCId", base_dimensions=["OCId"])
        ])

    # method to be overwritten
    def fit_generate_dimensions_and_make_dataset(self,train_ts:pd.DataFrame, fh:int, predict_window_length:int) -> Tuple[pd.Series, pd.DataFrame]:
        train_ts_ex = self.chain.fit_transform(train_ts)
        #[fh:] and [:-fh] is needed to avoid look ahead. However, it is needed only in fit_(...)_dataset beacuse this
        # function gets train_ts and transforms it into features and labels. predict_(...)_dataset gets predict_ts(X) and
        # test_df (Y) separately. SWE ensres that those two sets do not overlap in time domain
        train_ds_y = train_ts_ex.iloc[fh:]["y"] # y contains ground truth
        train_ds_x = train_ts_ex.iloc[:-fh] # it contains features generated by chain transform and y observations
        return train_ds_y, train_ds_x

    # method to be overwritten
    def predict_generate_dimensions_and_make_dataset(self, predict_ts:pd.DataFrame, test_ts:pd.DataFrame, fh:int) -> Tuple[pd.Series, pd.DataFrame]:
        #print("predict_ts.shape", predict_ts.shape, "self.predict_window_length_", self.predict_window_length_)
        test_ts_ex = self.chain.transform(predict_ts)

        test_ds_y = test_ts # test_df is a series containing ground truth
        test_ds_x = test_ts_ex # it contains features generated by chain transform and y observations

        return test_ds_y, test_ds_x

def create_keras_model(input_shape, output_shape, hidded_layers=(20,20,20), optimizer='adam',
                 kernel_initializer='glorot_uniform'):
    model = Sequential()
    model.add(Input(shape=input_shape))
    for hidded_layer in hidded_layers:
        model.add(Dense(hidded_layer,activation='relu',kernel_initializer=kernel_initializer))
    model.add(Dense(output_shape,kernel_initializer=kernel_initializer))
    model.compile(loss='mean_absolute_error',optimizer=optimizer, metrics=['mean_squared_error'], steps_per_execution=10)
    return model

if __name__ == "__main__":
    file_path = "/".join(os.path.abspath(__file__).split("/")[:-2] + ["../datasets/dataset.csv"])
    dataset = pd.read_csv(file_path, low_memory=False)
    # self.full_data = self.full_data[30:]
    dataset['timestamp'] = pd.to_datetime(dataset['timestamp'])
    dataset.index = dataset['timestamp']
    dataset.drop(columns=["timestamp"], inplace=True)
    dataset = dataset[:2*360*288].loc["2020-04-18":]

    print(dataset.columns)

    for instance in range(0,1):
        latitude_degrees = dataset[f"{instance}_Latitude"][0]
        longitude_degrees = dataset[f"{instance}_Longitude"][0]

        df = pd.DataFrame({}, index=dataset.index)
        df["PV production"] = dataset[f"{instance}_Power"]
        df["PV production"] = RollingAverage(window_size=6).fit_transform(df["PV production"])

        swe = SWE(latitude_degrees=latitude_degrees, longitude_degrees=longitude_degrees)
        swe.register_dataset(df)
        # swe.register_model(MLPRegressor(hidden_layer_sizes=(20, 20, 20), max_iter=500, random_state=0), "MLP", ["y", "SolarDay%", "qACId"])

        predictions_df = pd.DataFrame()
        metrics_df = pd.DataFrame()

        # swe.register_metric(mean_absolute_error, "MAE")
        # swe.register_metric(mean_squared_error, "MSE")
        # swe.register_metric(mean_absolute_percentage_error, "MAPE")
        # swe.register_metric(max_error, "ME")
        #
        # swe.summary()
        # swe()
        # plotter = swe.show_results()
        # plotter2 = swe.show_fit_dimensions()
        data = swe.get_fit_dimensions(dimensions=['PV production', 'Averaged pv production', 'PV profile', 'OCI', 'OCId', 'qOCId', 'DB0', 'DB1', 'DB2', 'DB3', 'DB4'])
        data = data.loc["2020-05-10":"2020-05-12"]
        fig, ax = plt.subplots(2)
        ax[0].plot(data.index,data['PV production'], label='PV production')
        ax[0].plot(data.index,data['Averaged pv production'], label='Averaged pv production')
        ax[0].plot(data.index,data['PV profile'], label='PV profile')

        ax[0].plot(data.index,data['OCI'], c='r', label='OCI')
        ax[1].plot(data.index,data['OCId'], c='m', label='OCId')
        # ax[1].plot(data.index,data['qOCId'])
        for i in range(5):
            ax[1].plot(data.index,data[f"DB{i}"], c='black', label="DB" if i == 0 else "_")
        # ax[0].legend()
        myFmt = mdates.DateFormatter('%H:%M %d.%m.%y')
        ax[0].set_ylabel("Power [kW]")
        ax[1].set_xlabel("Time")
        ax[1].set_ylabel("OCI [kW]")
        ax[0].set_xticklabels([])
        ax[0].xaxis.set_tick_params(rotation=30)
        ax[1].xaxis.set_major_formatter(myFmt)
        fig.legend()
        fig.show()

    plt.show()
